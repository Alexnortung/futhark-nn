{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-hierarchy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "portuguese-jason",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.benchmark as benchmark\n",
    "\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "worst-queens",
   "metadata": {},
   "outputs": [],
   "source": [
    "def each_label(l):\n",
    "    inner = [0.0] * 10\n",
    "    inner[int(l)] = 1\n",
    "    return inner\n",
    "\n",
    "def format_labels(labels):\n",
    "    ret_arr = []\n",
    "    for i in range(len(labels)):\n",
    "        ret_arr.append(each_label(labels[i]))\n",
    "    #return map(each_label, labels)\n",
    "    return ret_arr\n",
    "\n",
    "def argmax(arr):\n",
    "    acc = 0\n",
    "    for i in range(len(arr)):\n",
    "        if arr[acc] < arr[i]:\n",
    "            acc = i\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "solved-edition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up JSON Function\n",
    "import json\n",
    "\n",
    "# Open our JSON file and load it into python\n",
    "input_file = open ('../mnist-json/test-images-futhark.json')\n",
    "test_images = torch.tensor(json.load(input_file))\n",
    "input_file = open ('../mnist-json/test-labels-futhark.json')\n",
    "test_labels = torch.tensor(format_labels(json.load(input_file)))\n",
    "input_file = open ('../mnist-json/training-images-futhark.json')\n",
    "training_images = torch.tensor(json.load(input_file))\n",
    "input_file = open ('../mnist-json/training-labels-futhark.json')\n",
    "training_labels = torch.tensor(format_labels(json.load(input_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "japanese-multiple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create network\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(1),\n",
    "            nn.Linear(12 * 12 * 64, 128),\n",
    "            #nn.Linear(15360, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "practical-classroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = NeuralNetwork().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "phantom-momentum",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_fwd = model(training_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "related-inflation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 10])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_fwd.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "satisfactory-commercial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.4976e-03, 5.7604e-05, 9.4133e-05, 1.3860e-05, 1.8291e-06, 1.5349e-06,\n",
       "         9.9723e-01, 9.8136e-05, 4.5356e-08, 1.0104e-05],\n",
       "        [3.3367e-05, 6.3968e-09, 1.4203e-06, 4.0046e-08, 5.4766e-11, 4.3241e-09,\n",
       "         9.9996e-01, 6.4559e-06, 1.1431e-10, 1.0996e-09],\n",
       "        [2.8063e-02, 2.5476e-07, 1.9963e-06, 8.6563e-05, 6.4093e-06, 4.9326e-09,\n",
       "         9.6663e-01, 5.2076e-03, 4.9687e-06, 3.5841e-07],\n",
       "        [6.3701e-05, 2.0526e-07, 1.3393e-08, 2.0957e-08, 6.4437e-10, 6.0507e-09,\n",
       "         9.9991e-01, 2.1101e-05, 8.4372e-09, 1.3051e-08],\n",
       "        [3.0920e-02, 5.7860e-04, 5.2051e-05, 3.6486e-05, 1.5025e-05, 2.2232e-01,\n",
       "         4.4909e-01, 2.9625e-01, 1.2766e-07, 7.3977e-04],\n",
       "        [1.6836e-01, 1.2606e-05, 9.8838e-05, 1.0272e-07, 1.6224e-08, 6.9759e-07,\n",
       "         8.3101e-01, 5.1571e-04, 1.3239e-09, 5.8937e-07],\n",
       "        [2.4920e-01, 1.0479e-01, 1.4665e-03, 9.9933e-03, 2.0768e-02, 2.6732e-02,\n",
       "         5.3742e-01, 2.5464e-02, 4.7113e-07, 2.4165e-02],\n",
       "        [1.0672e-06, 3.1173e-08, 2.8376e-09, 4.3996e-10, 1.7537e-11, 3.2396e-13,\n",
       "         1.0000e+00, 1.8184e-06, 1.8764e-11, 2.6379e-10],\n",
       "        [5.5352e-02, 1.3395e-01, 1.5394e-03, 9.8959e-03, 1.2242e-02, 8.7658e-02,\n",
       "         6.0330e-01, 7.5876e-02, 4.4497e-06, 2.0191e-02],\n",
       "        [2.9147e-04, 1.0632e-05, 4.7082e-06, 4.5666e-06, 1.9682e-07, 1.6331e-06,\n",
       "         9.9884e-01, 8.4485e-04, 4.2737e-07, 2.2215e-08],\n",
       "        [6.6270e-03, 1.2823e-03, 4.7814e-05, 3.4115e-07, 1.5011e-06, 2.6675e-06,\n",
       "         9.9167e-01, 3.6049e-04, 1.7976e-08, 3.2632e-06],\n",
       "        [1.4355e-04, 3.5549e-06, 6.8283e-07, 5.2158e-09, 4.3726e-10, 6.8350e-07,\n",
       "         9.9984e-01, 1.2430e-05, 4.3325e-09, 1.0274e-07],\n",
       "        [2.8284e-03, 1.7369e-06, 2.4333e-05, 3.1845e-07, 6.3589e-07, 6.7105e-09,\n",
       "         9.9709e-01, 5.3634e-05, 7.6277e-11, 8.7218e-09],\n",
       "        [1.2147e-01, 5.5375e-08, 6.9997e-06, 1.3544e-07, 3.8946e-08, 2.4279e-05,\n",
       "         8.7849e-01, 2.8597e-06, 6.7297e-10, 1.1928e-05],\n",
       "        [1.3173e-01, 5.1172e-02, 1.5192e-03, 4.7707e-03, 1.1457e-03, 2.2443e-01,\n",
       "         4.8689e-01, 9.5007e-02, 8.6155e-07, 3.3365e-03],\n",
       "        [8.4314e-02, 4.0593e-04, 1.8376e-04, 7.7985e-05, 3.1709e-06, 1.8702e-05,\n",
       "         7.3179e-01, 1.8321e-01, 4.5429e-08, 8.0673e-07],\n",
       "        [1.3936e-03, 1.3677e-06, 7.7799e-05, 5.9320e-07, 1.6126e-08, 1.1178e-08,\n",
       "         9.9851e-01, 1.0729e-05, 6.3369e-09, 1.3576e-06],\n",
       "        [4.0156e-03, 5.8314e-06, 2.5054e-06, 9.9802e-07, 4.1391e-08, 9.1484e-08,\n",
       "         9.9104e-01, 4.9374e-03, 1.4265e-08, 1.4159e-08],\n",
       "        [1.6020e-01, 9.2332e-04, 4.4563e-05, 6.8451e-03, 5.6502e-05, 1.7160e-04,\n",
       "         7.2595e-01, 1.0477e-01, 4.4281e-05, 9.9579e-04],\n",
       "        [8.4896e-02, 1.9874e-02, 9.0631e-05, 1.6869e-04, 8.4896e-05, 2.8014e-04,\n",
       "         7.8173e-01, 1.1269e-01, 6.2183e-07, 1.8773e-04]],\n",
       "       grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_fwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "dental-lodging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 10]) torch.Size([20, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.1571, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = torch.nn.MSELoss()\n",
    "#loss_fn(, training_labels)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "print(first_fwd.size(), training_labels.size())\n",
    "# First loss\n",
    "loss_fn(first_fwd, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "powerful-cornell",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch():\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    \n",
    "    #optimizer.zero_grad()\n",
    "    outputs = model(training_images)\n",
    "    \n",
    "    loss = loss_fn(outputs, training_labels)\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "productive-alliance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1400, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch()\n",
    "\n",
    "    # We don't need gradients on to do reporting\n",
    "    model.train(False)\n",
    "\n",
    "avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "comprehensive-financing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1600, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(model(test_images), test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "postal-immune",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.benchmark as benchmark\n",
    "\n",
    "# BENCHMARKING\n",
    "def train_model(iterations=50):\n",
    "    model = NeuralNetwork().to(device)\n",
    "    for i in range(iterations):\n",
    "        # Make sure gradient tracking is on, and do a pass over the data\n",
    "        model.train(True)\n",
    "        avg_loss = train_one_epoch()\n",
    "\n",
    "        # We don't need gradients on to do reporting\n",
    "        model.train(False)\n",
    "    # Model is trained now\n",
    "    # Find accuracy\n",
    "    labels = list(map(argmax, test_labels))\n",
    "    output = model(test_images)\n",
    "    predictions = list(map(argmax, output))\n",
    "    hits = 0\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] == labels[i]:\n",
    "            hits += 1\n",
    "    accuracy = hits / len(predictions)\n",
    "    return accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "indie-replacement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7f3408727070>\n",
      "train_model()\n",
      "setup: from __main__ import train_model\n",
      "  3.15 s\n",
      "  1 measurement, 2 runs , 1 thread\n"
     ]
    }
   ],
   "source": [
    "t0 = benchmark.Timer(\n",
    "    stmt='train_model()',\n",
    "    setup='from __main__ import train_model',\n",
    "    globals={'NeuralNetwork': NeuralNetwork, \n",
    "             'device': device,\n",
    "             'test_images': test_images,\n",
    "             'test_labels': test_labels})\n",
    "\n",
    "\n",
    "print(t0.timeit(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
